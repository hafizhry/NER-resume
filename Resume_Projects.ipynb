{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume Projects.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPq/gCNDjhMFMvxHt9z7naR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafizhry/NER-resume/blob/main/Resume_Projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3sJrHKQ0Nd"
      },
      "source": [
        "'''\n",
        "Requirement.txt\n",
        "Python 3.7.11\n",
        "Spacy 2.1.4\n",
        "PyMuPDF 1.18.15\n",
        "'''"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU82xxGRG5Ml",
        "outputId": "292b55db-917d-48db-ecb0-95db69e531ed"
      },
      "source": [
        "!pip install spacy==2.1.4"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy==2.1.4 in /usr/local/lib/python3.7/dist-packages (2.1.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.5)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (7.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.19.5)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2.10)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.4) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7XJ_rfWvzvY",
        "outputId": "f32b9034-dbbc-4898-bcf7-f1097f5e9b82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-6_X7YtGQkI",
        "outputId": "ad828c5b-77da-41d9-bec6-c150b985e5f0"
      },
      "source": [
        "!pip install PyMuPDF"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.7/dist-packages (1.18.15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBU46x2yaxkS"
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "import sys, fitz\n",
        "import os\n",
        "from google.colab import files\n",
        "from spacy.util import minibatch, compounding\n",
        "#from spacy.gold import GoldParse\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF1Ip4Ft0CXZ"
      },
      "source": [
        "def open_dataset(file_path):\n",
        "  '''\n",
        "    Function to open JSON dataset and assign it to a list which consist\n",
        "    of the resume and it's NER entities. The function recieve an input with the form of\n",
        "    JSON file of the dataset and gives an output of dataset in form of a list.\n",
        "    The output list has the structure of [text, {'entities':[(start_point, end_point, 'labels')]}]\n",
        "\n",
        "    The dataset has 220 items of which 220 items have been manually labeled.\n",
        "    The labels are divided into following 10 categories:\n",
        "    Name\n",
        "    College Name\n",
        "    Degree\n",
        "    Graduation Year\n",
        "    Years of Experience\n",
        "    Companies worked at\n",
        "    Designation\n",
        "    Skills\n",
        "    Location\n",
        "    Email Address\n",
        "    \n",
        "    Source : https://www.kaggle.com/dataturks/resume-entities-for-ner\n",
        "  '''\n",
        "  dataset = []\n",
        "  lines = []\n",
        "  with open(file_path,) as f:\n",
        "    lines = f.readlines() \n",
        "    print('Number of data: ' + str(len(lines)))\n",
        "    for line in lines:\n",
        "      data = json.loads(line) # loads the JSON files\n",
        "      text = data['content'] # assign the content of the resume to list (as text)\n",
        "      entities = []\n",
        "      for annotation in data['annotation']: # loop for assigning each label, start and end points of the NER label to the list (as entities)\n",
        "        point = annotation['points'][0]\n",
        "        labels = annotation['label']\n",
        "        if not isinstance(labels, list):\n",
        "          labels = list(labels)\n",
        "        for label in labels:\n",
        "          entities.append((point['start'], point['end']+1, label))\n",
        "      \n",
        "      dataset.append((text, {'entities':entities}))\n",
        "  return dataset"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kn_YMqs5k1X",
        "outputId": "7fa44c95-69fd-460f-eb44-aca4b509e4d0"
      },
      "source": [
        "data = open_dataset('/content/Entity Recognition in Resumes.json')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data: 220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti0PLUb46cds",
        "outputId": "d8dff78e-9280-44f4-d5ae-6c194e73701a"
      },
      "source": [
        "data[0]\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Abhishek Jha\\nApplication Development Associate - Accenture\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n\\n• To work for an organization which provides me the opportunity to improve my skills\\nand knowledge for my individual and company's growth in best possible ways.\\n\\nWilling to relocate to: Bangalore, Karnataka\\n\\nWORK EXPERIENCE\\n\\nApplication Development Associate\\n\\nAccenture -\\n\\nNovember 2017 to Present\\n\\nRole: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries\\nfor the Bot which will be triggered based on given input. Also, Training the bot for different possible\\nutterances (Both positive and negative), which will be given as\\ninput by the user.\\n\\nEDUCATION\\n\\nB.E in Information science and engineering\\n\\nB.v.b college of engineering and technology -  Hubli, Karnataka\\n\\nAugust 2013 to June 2017\\n\\n12th in Mathematics\\n\\nWoodbine modern school\\n\\nApril 2011 to March 2013\\n\\n10th\\n\\nKendriya Vidyalaya\\n\\nApril 2001 to March 2011\\n\\nSKILLS\\n\\nC (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Skills\\n\\nhttps://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player\",\n",
              " {'entities': [(1295, 1622, 'Skills'),\n",
              "   (993, 1154, 'Skills'),\n",
              "   (939, 957, 'College Name'),\n",
              "   (883, 905, 'College Name'),\n",
              "   (856, 861, 'Graduation Year'),\n",
              "   (771, 814, 'College Name'),\n",
              "   (727, 770, 'Designation'),\n",
              "   (407, 416, 'Companies worked at'),\n",
              "   (372, 405, 'Designation'),\n",
              "   (95, 146, 'Email Address'),\n",
              "   (60, 69, 'Location'),\n",
              "   (49, 58, 'Companies worked at'),\n",
              "   (13, 46, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewZInZ1UL70Y"
      },
      "source": [
        "def cleaning_dataset(data):\n",
        "  '''\n",
        "    Function to clean the dataset. This function recived an input of the dataset\n",
        "    in the form of list and gives an output of a list as well. The function itself\n",
        "    clean the '/n' element from the resume text, lowered the case, and also\n",
        "    checks the validation of the entity start and end points to the text of the resume.\n",
        "\n",
        "    This function is inspired by https://www.kaggle.com/mohamedtaha7/ner-on-resumes-using-spacy \n",
        "  '''\n",
        "  invalid_span_tokens = re.compile(r'\\s')\n",
        "  cleaned_data = []\n",
        "  for text, annotations in data:\n",
        "      entities = annotations['entities']\n",
        "      valid_entities = []\n",
        "      cleaned_text = ' '.join(text.split('\\n')) # replacing the '\\n' element to whitespaces\n",
        "      cleaned_text = cleaned_text.lower() # lower case the text data\n",
        "      for start, end, label in entities:\n",
        "          valid_start = start\n",
        "          valid_end = end\n",
        "          # this loop validates the start and end point of the entities to the text dataset \n",
        "          while valid_start < len(text) and invalid_span_tokens.match( \n",
        "                  text[valid_start]):\n",
        "              valid_start += 1\n",
        "          while valid_end > 1 and invalid_span_tokens.match(\n",
        "                  text[valid_end - 1]):\n",
        "              valid_end -= 1\n",
        "          valid_entities.append([valid_start, valid_end, label])\n",
        "      cleaned_data.append([cleaned_text, {'entities': valid_entities}])\n",
        "  return cleaned_data"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJZn_5RbN9ZP"
      },
      "source": [
        "cleaned_data = cleaning_dataset(data)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tw3BTsW9_W0"
      },
      "source": [
        "def train_data_spacy(train_data):\n",
        "  '''\n",
        "    This function trains the NLP model using Spacy. The model recieves an input\n",
        "    of training data in the form of a list. The training data consist of a resume\n",
        "    text and entities that describes the labels (annotation) of the text. \n",
        "  '''\n",
        "  nlp = English()\n",
        "  if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "  else: \n",
        "    ner = nlp.get_pipe('ner')\n",
        "\n",
        "  for _, annotation in train_data:\n",
        "      for annot in annotation['entities']:\n",
        "        ner.add_label(annot[2])\n",
        "  \n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    n_iter = 50\n",
        "    \n",
        "    for itn in range(n_iter):\n",
        "      print('Iteration ' + str(itn))\n",
        "      random.shuffle(train_data)\n",
        "      losses = {}\n",
        "      for batch in spacy.util.minibatch(train_data, size=2):\n",
        "        texts = [text for text, annotation in batch]\n",
        "        annotations = [annotation for text, annotation in batch] \n",
        "        try:\n",
        "          nlp.update(\n",
        "                texts, \n",
        "                annotations,\n",
        "                drop=0.3,\n",
        "                sgd=optimizer,\n",
        "                losses=losses)\n",
        "        except Exception as e:\n",
        "          pass\n",
        "      print(\"Losses\", losses)\n",
        "    \n",
        "  nlp.to_disk('models')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nK7cXs173v2",
        "outputId": "29be4934-1cd3-4b45-aabc-90591df83db1"
      },
      "source": [
        "train_data_spacy(cleaned_data)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "Losses {'ner': 31600.52429742074}\n",
            "Iteration 1\n",
            "Losses {'ner': 21137.05883979446}\n",
            "Iteration 2\n",
            "Losses {'ner': 18011.905975277114}\n",
            "Iteration 3\n",
            "Losses {'ner': 17350.174877381356}\n",
            "Iteration 4\n",
            "Losses {'ner': 15705.336480165304}\n",
            "Iteration 5\n",
            "Losses {'ner': 14178.736576130508}\n",
            "Iteration 6\n",
            "Losses {'ner': 12968.93688420851}\n",
            "Iteration 7\n",
            "Losses {'ner': 11808.980309726967}\n",
            "Iteration 8\n",
            "Losses {'ner': 10396.981286817761}\n",
            "Iteration 9\n",
            "Losses {'ner': 11289.080773398444}\n",
            "Iteration 10\n",
            "Losses {'ner': 10991.040005158824}\n",
            "Iteration 11\n",
            "Losses {'ner': 10396.361354378258}\n",
            "Iteration 12\n",
            "Losses {'ner': 10179.293207149705}\n",
            "Iteration 13\n",
            "Losses {'ner': 9042.717718382433}\n",
            "Iteration 14\n",
            "Losses {'ner': 9761.41774862583}\n",
            "Iteration 15\n",
            "Losses {'ner': 9401.479164277207}\n",
            "Iteration 16\n",
            "Losses {'ner': 8367.054381859714}\n",
            "Iteration 17\n",
            "Losses {'ner': 8708.115090990948}\n",
            "Iteration 18\n",
            "Losses {'ner': 7719.056371388364}\n",
            "Iteration 19\n",
            "Losses {'ner': 10943.083217549494}\n",
            "Iteration 20\n",
            "Losses {'ner': 9058.893553562737}\n",
            "Iteration 21\n",
            "Losses {'ner': 8441.467394227948}\n",
            "Iteration 22\n",
            "Losses {'ner': 7638.927772345605}\n",
            "Iteration 23\n",
            "Losses {'ner': 7921.604596423798}\n",
            "Iteration 24\n",
            "Losses {'ner': 8034.843511390665}\n",
            "Iteration 25\n",
            "Losses {'ner': 7852.822242420725}\n",
            "Iteration 26\n",
            "Losses {'ner': 6720.239308655243}\n",
            "Iteration 27\n",
            "Losses {'ner': 7526.4342369409}\n",
            "Iteration 28\n",
            "Losses {'ner': 6584.7671603615045}\n",
            "Iteration 29\n",
            "Losses {'ner': 6954.678186823371}\n",
            "Iteration 30\n",
            "Losses {'ner': 6074.413605082867}\n",
            "Iteration 31\n",
            "Losses {'ner': 6967.715244983567}\n",
            "Iteration 32\n",
            "Losses {'ner': 8198.029135640394}\n",
            "Iteration 33\n",
            "Losses {'ner': 6268.768814222528}\n",
            "Iteration 34\n",
            "Losses {'ner': 6513.393811203629}\n",
            "Iteration 35\n",
            "Losses {'ner': 5784.73708665212}\n",
            "Iteration 36\n",
            "Losses {'ner': 6711.747206244569}\n",
            "Iteration 37\n",
            "Losses {'ner': 5791.151717062334}\n",
            "Iteration 38\n",
            "Losses {'ner': 6448.700540183067}\n",
            "Iteration 39\n",
            "Losses {'ner': 7098.797155809269}\n",
            "Iteration 40\n",
            "Losses {'ner': 6701.5674646595335}\n",
            "Iteration 41\n",
            "Losses {'ner': 7050.275335912804}\n",
            "Iteration 42\n",
            "Losses {'ner': 7215.739694996807}\n",
            "Iteration 43\n",
            "Losses {'ner': 6689.541806703061}\n",
            "Iteration 44\n",
            "Losses {'ner': 6635.158703048252}\n",
            "Iteration 45\n",
            "Losses {'ner': 5649.169758158191}\n",
            "Iteration 46\n",
            "Losses {'ner': 6305.822599072064}\n",
            "Iteration 47\n",
            "Losses {'ner': 6338.913589498252}\n",
            "Iteration 48\n",
            "Losses {'ner': 5896.17985649271}\n",
            "Iteration 49\n",
            "Losses {'ner': 6069.09758428164}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azyl4r0fBlUv"
      },
      "source": [
        "def upload_resume():\n",
        "  '''\n",
        "  This function enables user to upload and test the models with their own resume.\n",
        "  It only recieves a resume with the format of PDF\n",
        "  '''\n",
        "  base_dir = '/content'\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print(os.path.join(base_dir, fn))\n",
        "    doc = fitz.open(os.path.join(base_dir, fn))\n",
        "  text = ''\n",
        "  for page in doc:\n",
        "    text = text + str(page.getText())\n",
        "    tx = ' '.join(text.split('\\n'))\n",
        "  \n",
        "  nlp_model = spacy.load('models') # load the previous trained model\n",
        "  test = nlp_model(tx) # predict the input resume based on the model\n",
        "  for ent in test.ents:\n",
        "    print(f'{ent.label_.upper():{20}}- {ent.text}')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "UGCPOZCr3F1v",
        "outputId": "c130d595-64e5-4307-eadc-09b6130aab1c"
      },
      "source": [
        "upload_resume()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b385018c-f001-44bc-82d7-f49e93517bb4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b385018c-f001-44bc-82d7-f49e93517bb4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Yusuf, Hafizh Rahmatdianto_Resume_OVO.pdf to Yusuf, Hafizh Rahmatdianto_Resume_OVO (1).pdf\n",
            "/content/Yusuf, Hafizh Rahmatdianto_Resume_OVO.pdf\n",
            "NAME                - Hafizh Rahmatdianto\n",
            "DESIGNATION         - Yusuf\n",
            "SKILLS              - programming, database manipulation, analytical thinking, and creative problem solving. Experienced at creating predictive models  for health-related problems. Strong attention to detail and possessing a significant ability to work in team environments, having led  student union organization during college period. Looking for a position related to data analytics or business intelligence.\n",
            "DEGREE              - Bachelor of Biomedical Engineering\n",
            "SKILLS              - Programming\n",
            "SKILLS              - Language\n",
            "SKILLS              - Databases  (MySQL)\n",
            "COMPANIES WORKED AT - Microsoft\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}